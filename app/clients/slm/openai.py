"""OpenAI-based SLM client using the Chat Completions API."""

from __future__ import annotations

import json
from typing import Any

import httpx
import structlog

from app.clients.slm.base import GeneratedAnswer, SLMClient
from app.clients.slm.local import LocalSLM
from app.models import Hypothesis, MediaType


logger = structlog.get_logger()


class OpenAISLM(SLMClient):
    """SLM client backed by OpenAI's chat/vision models."""

    def __init__(
        self,
        api_key: str,
        model: str,
        vision_model: str | None = None,
        base_url: str | None = None,
        timeout: float = 60.0,
    ) -> None:
        if not api_key:
            raise ValueError("OpenAI API key is required for OpenAISLM")

        self.model = model
        self.vision_model = vision_model or model
        self.base_url = (base_url.rstrip("/") if base_url else "https://api.openai.com/v1")

        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

        self.client = httpx.AsyncClient(base_url=self.base_url, timeout=timeout, headers=headers)
        self.fallback = LocalSLM()

    async def generate_hypotheses(
        self,
        user_input: str | None,
        context: dict[str, Any],
        count: int = 3,
        media_type: MediaType = MediaType.TEXT,
        media_url: str | None = None,
        media_base64: str | None = None,
    ) -> list[Hypothesis]:
        """Generate intent hypotheses using OpenAI chat completions."""

        messages = self._build_hypothesis_messages(
            user_input, context, count, media_type, media_url, media_base64
        )

        try:
            response = await self._post_chat_completion(
                {
                    "model": self.model,
                    "messages": messages,
                    "temperature": 0.6,
                    "max_tokens": 700,
                    "response_format": {"type": "json_object"},
                }
            )

            payload = self._extract_json_content(response)
            hypotheses_payload = payload.get("hypotheses", [])

            hypotheses: list[Hypothesis] = []
            for idx, item in enumerate(hypotheses_payload[:count]):
                question = item.get("question") or item.get("query")
                if not question:
                    continue

                rationale = item.get("rationale") or "Generated by OpenAI"
                confidence = float(item.get("confidence", 0.7))

                hypotheses.append(
                    Hypothesis(
                        id=item.get("id", f"h{idx + 1}"),
                        question=question,
                        rationale=rationale,
                        confidence=max(0.0, min(1.0, confidence)),
                    )
                )

            if hypotheses:
                return hypotheses

        except Exception as exc:  # noqa: BLE001
            logger.warning("openai_hypothesis_generation_failed", error=str(exc))

        # Fallback to local heuristic implementation
        return await self.fallback.generate_hypotheses(
            user_input, context, count, media_type, media_url, media_base64
        )

    async def summarize(self, text: str, max_tokens: int) -> str:
        messages = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "You are a concise assistant that summarizes content while preserving\n"
                            "critical details. Respond with plain text only."
                        ),
                    }
                ],
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            f"Summarize the following content in approximately {max_tokens} tokens:\n\n{text}"
                        ),
                    }
                ],
            },
        ]

        try:
            response = await self._post_chat_completion(
                {
                    "model": self.model,
                    "messages": messages,
                    "temperature": 0.2,
                    "max_tokens": max_tokens,
                }
            )

            return self._extract_text_content(response)

        except Exception as exc:  # noqa: BLE001
            logger.warning("openai_summarize_failed", error=str(exc))
            return await self.fallback.summarize(text, max_tokens)

    async def describe_media(
        self,
        media_type: MediaType,
        media_url: str | None = None,
        media_base64: str | None = None,
    ) -> dict[str, Any]:
        if media_type != MediaType.IMAGE:
            return await self.fallback.describe_media(media_type, media_url, media_base64)

        messages = self._build_media_messages(media_url, media_base64)

        try:
            response = await self._post_chat_completion(
                {
                    "model": self.vision_model,
                    "messages": messages,
                    "temperature": 0.2,
                    "max_tokens": 400,
                    "response_format": {"type": "json_object"},
                }
            )

            payload = self._extract_json_content(response)
            caption = payload.get("caption") or payload.get("description")
            tags = payload.get("tags") or []

            if isinstance(tags, str):
                tags = [tag.strip() for tag in tags.split(",") if tag.strip()]

            if not isinstance(tags, list):
                tags = []

            if not caption:
                caption = "Image provided by the user"

            if not tags:
                tags = ["image"]

            return {"caption": caption, "tags": tags}

        except Exception as exc:  # noqa: BLE001
            logger.warning("openai_describe_media_failed", error=str(exc))
            return await self.fallback.describe_media(media_type, media_url, media_base64)

    async def generate_answer(
        self,
        prompt: str,
        response_format: dict[str, Any] | None = None,
    ) -> GeneratedAnswer:
        messages = [
            {
                "role": "system",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            "You are an expert teacher who provides structured, high-signal answers."
                            " Return JSON with keys: answer (string), supporting_points (array of strings), confidence (0-1)."
                        ),
                    }
                ],
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": prompt,
                    }
                ],
            },
        ]

        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": 0.2,
            "max_tokens": 900,
            "response_format": response_format or {"type": "json_object"},
        }

        try:
            response = await self._post_chat_completion(payload)
            data = self._extract_json_content(response)
            answer = data.get("answer") or prompt
            supporting = data.get("supporting_points") or []
            confidence = float(data.get("confidence", 0.0))

            if isinstance(supporting, str):
                supporting = [supporting]

            return GeneratedAnswer(
                answer=answer,
                supporting_points=list(supporting),
                confidence=max(0.0, min(1.0, confidence)),
            )

        except Exception as exc:  # noqa: BLE001
            logger.warning("openai_answer_generation_failed", error=str(exc))
            return await self.fallback.generate_answer(prompt, response_format)

    async def close(self) -> None:
        await self.client.aclose()

    async def _post_chat_completion(self, payload: dict[str, Any]) -> dict[str, Any]:
        response = await self.client.post("/chat/completions", json=payload)
        response.raise_for_status()
        return response.json()

    def _extract_json_content(self, response: dict[str, Any]) -> dict[str, Any]:
        try:
            content = response["choices"][0]["message"]["content"]
            return json.loads(content)
        except (KeyError, IndexError, json.JSONDecodeError) as exc:
            raise RuntimeError("Failed to parse JSON content from OpenAI response") from exc

    def _extract_text_content(self, response: dict[str, Any]) -> str:
        try:
            return response["choices"][0]["message"]["content"].strip()
        except (KeyError, IndexError) as exc:
            raise RuntimeError("Failed to extract text content from OpenAI response") from exc

    def _build_hypothesis_messages(
        self,
        user_input: str | None,
        context: dict[str, Any],
        count: int,
        media_type: MediaType,
        media_url: str | None,
        media_base64: str | None,
    ) -> list[dict[str, Any]]:
        persona_desc = self._describe_persona(context.get("persona_facets", {}))

        context_parts: list[str] = []
        if context.get("recent_goals"):
            context_parts.append(f"Recent Goals: {', '.join(context['recent_goals'][:2])}")
        if context.get("preferences"):
            context_parts.append(f"Preferences: {', '.join(context['preferences'][:3])}")
        if context.get("styles"):
            context_parts.append(f"Style Inputs: {', '.join(context['styles'][:2])}")

        context_block = "\n".join(context_parts) if context_parts else "No additional context."

        user_content: list[dict[str, Any]] = [
            {
                "type": "text",
                "text": (
                    f"User Input: {user_input or '(no text input)'}\n"
                    f"Media Type: {media_type.value}\n"
                    f"Interaction Count: {context.get('interaction_count', 0)}\n"
                    f"Context:\n{context_block}\n\n"
                    f"Generate {count} clarification hypotheses in JSON with keys: id, question,"
                    " rationale, confidence (0-1)."
                ),
            }
        ]

        if media_type == MediaType.IMAGE:
            image_reference = media_url or media_base64
            if image_reference:
                user_content.append(
                    {
                        "type": "image_url",
                        "image_url": {"url": image_reference},
                    }
                )

        system_text = (
            "You are an expert instructor analysing visual and textual content."
            " Return JSON with a 'hypotheses' list. Each hypothesis must include:"
            " id (string), question (string), rationale (string), confidence (0-1 float)."
            " Craft the questions as proactive teacher-style prompts that anticipate"
            " what guidance or insight the learner would need next."
            " Questions must reference concrete elements visible in the content"
            " (names, metrics, text snippets, layout cues, etc.) and must not rely on"
            " generic phrasing such as 'this image' or 'the picture'."
            " Speak authoritatively, positioning the assistant as the teacher."
        )

        return [
            {"role": "system", "content": [{"type": "text", "text": system_text}]},
            {"role": "user", "content": user_content},
        ]

    def _build_media_messages(
        self,
        media_url: str | None,
        media_base64: str | None,
    ) -> list[dict[str, Any]]:
        user_content: list[dict[str, Any]] = [
            {
                "type": "text",
                "text": (
                    "Describe the image and return JSON with keys 'caption' and 'tags'."
                    " Tags should be a list of short descriptors such as 'image:screenshot'"
                    " or 'feature:dashboard'."
                ),
            }
        ]

        image_reference = media_url or media_base64
        if image_reference:
            user_content.append(
                {
                    "type": "image_url",
                    "image_url": {"url": image_reference},
                }
            )

        system_text = (
            "You are a vision model that outputs JSON objects describing images for downstream"
            " classification."
        )

        return [
            {"role": "system", "content": [{"type": "text", "text": system_text}]},
            {"role": "user", "content": user_content},
        ]

    def _describe_persona(self, facets: dict[str, float]) -> str:
        descriptions: list[str] = []

        if facets.get("concise", 0.5) > 0.7:
            descriptions.append("prefers concise responses")
        elif facets.get("concise", 0.5) < 0.3:
            descriptions.append("prefers detailed explanations")

        if facets.get("code_first", 0.5) > 0.7:
            descriptions.append("code-first approach")

        if facets.get("step_by_step", 0.5) > 0.7:
            descriptions.append("likes step-by-step guidance")

        if facets.get("formal", 0.5) > 0.7:
            descriptions.append("formal tone")
        elif facets.get("formal", 0.5) < 0.3:
            descriptions.append("casual tone")

        return ", ".join(descriptions) if descriptions else "balanced preferences"

